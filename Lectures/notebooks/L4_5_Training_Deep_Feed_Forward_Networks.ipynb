{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feed Forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 28*28 # MNIST\n",
    "h1 = 300 # hidden layer 1,2 size\n",
    "h2 = 100 \n",
    "num_out = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None, 10), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Function For Neuron Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, num_neurons, name, activation= None):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        variance = 2 / np.sqrt(num_inputs)\n",
    "        \n",
    "        W = tf.Variable(tf.truncated_normal((num_inputs, num_neurons), stddev=variance), name='weights')\n",
    "        b = tf.Variable(tf.zeros([num_neurons]), name='bias')\n",
    "        \n",
    "        z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is None:\n",
    "            return z\n",
    "\n",
    "        activation = activation.lower()\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(z)\n",
    "        elif activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(z)\n",
    "        elif activation == 'softmax':\n",
    "            return tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all layers of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(X, h1, name='hidden1', activation='ReLU')\n",
    "    hidden2 = neuron_layer(hidden1, h2, name='hidden2',activation='ReLU')\n",
    "    out = neuron_layer(hidden2, num_out, name='out', activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=out)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "\n",
    "    predictions = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Initializer and Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD MNIST AND TRAIN NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./tmp/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 64.11%\n",
      "Test set accuracy in epoch 2: 66.02%\n",
      "Test set accuracy in epoch 3: 66.5%\n",
      "Test set accuracy in epoch 4: 66.78%\n",
      "Test set accuracy in epoch 5: 67.0%\n",
      "Test set accuracy in epoch 6: 67.23%\n",
      "Test set accuracy in epoch 7: 67.35%\n",
      "Test set accuracy in epoch 8: 67.49%\n",
      "Test set accuracy in epoch 9: 67.7%\n",
      "Test set accuracy in epoch 10: 67.74%\n",
      "Test set accuracy in epoch 11: 67.89%\n",
      "Test set accuracy in epoch 12: 67.89%\n",
      "Test set accuracy in epoch 13: 67.98%\n",
      "Test set accuracy in epoch 14: 68.03%\n",
      "Test set accuracy in epoch 15: 68.06%\n",
      "Test set accuracy in epoch 16: 68.07%\n",
      "Test set accuracy in epoch 17: 68.15%\n",
      "Test set accuracy in epoch 18: 68.22%\n",
      "Test set accuracy in epoch 19: 68.22%\n",
      "Test set accuracy in epoch 20: 77.22%\n",
      "Test set accuracy in epoch 21: 77.52%\n",
      "Test set accuracy in epoch 22: 77.58%\n",
      "Test set accuracy in epoch 23: 77.69%\n",
      "Test set accuracy in epoch 24: 77.8%\n",
      "Test set accuracy in epoch 25: 77.79%\n",
      "Test set accuracy in epoch 26: 77.91%\n",
      "Test set accuracy in epoch 27: 77.94%\n",
      "Test set accuracy in epoch 28: 77.97%\n",
      "Test set accuracy in epoch 29: 77.99%\n",
      "Test set accuracy in epoch 30: 78.04%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(train_step, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: mnist.test.images, y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = saver.save(sess, './models/final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He Initialization + ELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_elu_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='he_elu_X')\n",
    "he_elu_y = tf.placeholder(tf.int64, shape=(None, 10), name='he_elu_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_elu_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        W = tf.Variable(initializer((num_inputs, num_neurons)), name='weights')\n",
    "        b = tf.Variable(tf.zeros([num_neurons]), name='he_elu_bias')\n",
    "        \n",
    "        z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is None:\n",
    "            return z\n",
    "\n",
    "        activation = activation.lower()\n",
    "        if activation == 'elu':\n",
    "            return tf.nn.elu(z)\n",
    "        elif activation == 'softmax':\n",
    "            return tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_dnn'):\n",
    "    he_elu_hidden1 = he_elu_neuron_layer(he_elu_X, h1, name='he_elu_hidden1', activation='elu')\n",
    "    he_elu_hidden2 = he_elu_neuron_layer(he_elu_hidden1, h2, name='he_elu_hidden2',activation='elu')\n",
    "    he_elu_out = he_elu_neuron_layer(he_elu_hidden2, num_out, name='he_elu_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_loss'):\n",
    "    he_elu_entropy = tf.losses.softmax_cross_entropy(onehot_labels=he_elu_y, logits=he_elu_out)\n",
    "    he_elu_loss = tf.reduce_mean(he_elu_entropy, name='he_elu_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('he_elu_train'):\n",
    "    he_elu_optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    he_elu_train_step = he_elu_optimizer.minimize(he_elu_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_eval'):\n",
    "\n",
    "    he_elu_predictions = tf.equal(tf.argmax(he_elu_out, 1), tf.argmax(he_elu_y, 1))\n",
    "    he_elu_accuracy = tf.reduce_mean(tf.cast(he_elu_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_elu_init = tf.global_variables_initializer()\n",
    "he_elu_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 72.8%\n",
      "Test set accuracy in epoch 2: 76.03%\n",
      "Test set accuracy in epoch 3: 81.1%\n",
      "Test set accuracy in epoch 4: 82.04%\n",
      "Test set accuracy in epoch 5: 82.61%\n",
      "Test set accuracy in epoch 6: 82.83%\n",
      "Test set accuracy in epoch 7: 90.48%\n",
      "Test set accuracy in epoch 8: 91.07%\n",
      "Test set accuracy in epoch 9: 91.19%\n",
      "Test set accuracy in epoch 10: 91.54%\n",
      "Test set accuracy in epoch 11: 91.77%\n",
      "Test set accuracy in epoch 12: 91.96%\n",
      "Test set accuracy in epoch 13: 92.11%\n",
      "Test set accuracy in epoch 14: 92.28%\n",
      "Test set accuracy in epoch 15: 92.44%\n",
      "Test set accuracy in epoch 16: 92.54%\n",
      "Test set accuracy in epoch 17: 92.69%\n",
      "Test set accuracy in epoch 18: 92.68%\n",
      "Test set accuracy in epoch 19: 92.71%\n",
      "Test set accuracy in epoch 20: 92.78%\n",
      "Test set accuracy in epoch 21: 92.91%\n",
      "Test set accuracy in epoch 22: 92.97%\n",
      "Test set accuracy in epoch 23: 93.07%\n",
      "Test set accuracy in epoch 24: 93.05%\n",
      "Test set accuracy in epoch 25: 93.22%\n",
      "Test set accuracy in epoch 26: 93.21%\n",
      "Test set accuracy in epoch 27: 93.29%\n",
      "Test set accuracy in epoch 28: 93.35%\n",
      "Test set accuracy in epoch 29: 93.42%\n",
      "Test set accuracy in epoch 30: 93.46%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    he_elu_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(he_elu_train_step, feed_dict={he_elu_X: X_batch, he_elu_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        he_elu_test_acc = sess.run(he_elu_accuracy, feed_dict={he_elu_X: mnist.test.images, he_elu_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(he_elu_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = he_elu_saver.save(sess, './models/he_elu_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='bn_X')\n",
    "bn_y = tf.placeholder(tf.int64, shape=(None, 10), name='bn_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        \n",
    "        if activation == 'elu':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=None, weights_initializer=initializer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            bn_dense = tf.contrib.layers.batch_norm(dense, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            elu = tf.nn.elu(bn_dense)\n",
    "            \n",
    "            return elu\n",
    "        \n",
    "        elif activation == 'softmax':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=tf.nn.softmax, weights_initializer=initializer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_dnn'):\n",
    "    bn_hidden1 = bn_neuron_layer(bn_X, h1, name='bn_hidden1', activation='elu')\n",
    "    bn_hidden2 = bn_neuron_layer(bn_hidden1, h2, name='bn_hidden2',activation='elu')\n",
    "    bn_out = bn_neuron_layer(bn_hidden2, num_out, name='bn_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_loss'):\n",
    "    bn_entropy = tf.losses.softmax_cross_entropy(onehot_labels=bn_y, logits=bn_out)\n",
    "    bn_loss = tf.reduce_mean(bn_entropy, name='bn_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('bn_train'):\n",
    "    bn_optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    bn_train_step = bn_optimizer.minimize(bn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_eval'):\n",
    "\n",
    "    bn_predictions = tf.equal(tf.argmax(bn_out, 1), tf.argmax(bn_y, 1))\n",
    "    bn_accuracy = tf.reduce_mean(tf.cast(bn_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_init = tf.global_variables_initializer()\n",
    "bn_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 87.65%\n",
      "Test set accuracy in epoch 2: 90.23%\n",
      "Test set accuracy in epoch 3: 91.11%\n",
      "Test set accuracy in epoch 4: 91.79%\n",
      "Test set accuracy in epoch 5: 92.31%\n",
      "Test set accuracy in epoch 6: 92.64%\n",
      "Test set accuracy in epoch 7: 92.99%\n",
      "Test set accuracy in epoch 8: 93.2%\n",
      "Test set accuracy in epoch 9: 93.35%\n",
      "Test set accuracy in epoch 10: 93.62%\n",
      "Test set accuracy in epoch 11: 93.64%\n",
      "Test set accuracy in epoch 12: 93.94%\n",
      "Test set accuracy in epoch 13: 94.18%\n",
      "Test set accuracy in epoch 14: 94.29%\n",
      "Test set accuracy in epoch 15: 94.48%\n",
      "Test set accuracy in epoch 16: 94.59%\n",
      "Test set accuracy in epoch 17: 94.83%\n",
      "Test set accuracy in epoch 18: 94.83%\n",
      "Test set accuracy in epoch 19: 94.82%\n",
      "Test set accuracy in epoch 20: 95.02%\n",
      "Test set accuracy in epoch 21: 95.28%\n",
      "Test set accuracy in epoch 22: 95.34%\n",
      "Test set accuracy in epoch 23: 95.45%\n",
      "Test set accuracy in epoch 24: 95.53%\n",
      "Test set accuracy in epoch 25: 95.71%\n",
      "Test set accuracy in epoch 26: 95.75%\n",
      "Test set accuracy in epoch 27: 95.83%\n",
      "Test set accuracy in epoch 28: 95.86%\n",
      "Test set accuracy in epoch 29: 96.08%\n",
      "Test set accuracy in epoch 30: 96.13%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    bn_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(bn_train_step, feed_dict={bn_X: X_batch, bn_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        bn_test_acc = sess.run(bn_accuracy, feed_dict={bn_X: mnist.test.images, bn_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(bn_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = bn_saver.save(sess, './models/bn_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='adam_X')\n",
    "adam_y = tf.placeholder(tf.int64, shape=(None, 10), name='adam_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_dnn'): # Using bn_neuron_layer because it does not change the netowrk feedforward is the same\n",
    "    adam_hidden1 = bn_neuron_layer(adam_X, h1, name='adam_hidden1', activation='elu')\n",
    "    adam_hidden2 = bn_neuron_layer(adam_hidden1, h2, name='adam_hidden2',activation='elu')\n",
    "    adam_out = bn_neuron_layer(adam_hidden2, num_out, name='adam_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_loss'):\n",
    "    adam_entropy = tf.losses.softmax_cross_entropy(onehot_labels=adam_y, logits=adam_out)\n",
    "    adam_loss = tf.reduce_mean(adam_entropy, name='adam_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('adam_train'):\n",
    "    adam_optimizer = tf.train.AdamOptimizer(learning_rate=eta)\n",
    "    adam_train_step = adam_optimizer.minimize(adam_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_eval'):\n",
    "\n",
    "    adam_predictions = tf.equal(tf.argmax(adam_out, 1), tf.argmax(adam_y, 1))\n",
    "    adam_accuracy = tf.reduce_mean(tf.cast(adam_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_init = tf.global_variables_initializer()\n",
    "adam_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 92.7%\n",
      "Test set accuracy in epoch 2: 94.93%\n",
      "Test set accuracy in epoch 3: 95.71%\n",
      "Test set accuracy in epoch 4: 95.92%\n",
      "Test set accuracy in epoch 5: 96.47%\n",
      "Test set accuracy in epoch 6: 96.38%\n",
      "Test set accuracy in epoch 7: 96.25%\n",
      "Test set accuracy in epoch 8: 96.5%\n",
      "Test set accuracy in epoch 9: 96.55%\n",
      "Test set accuracy in epoch 10: 97.07%\n",
      "Test set accuracy in epoch 11: 96.5%\n",
      "Test set accuracy in epoch 12: 96.61%\n",
      "Test set accuracy in epoch 13: 96.87%\n",
      "Test set accuracy in epoch 14: 96.44%\n",
      "Test set accuracy in epoch 15: 96.89%\n",
      "Test set accuracy in epoch 16: 96.98%\n",
      "Test set accuracy in epoch 17: 96.98%\n",
      "Test set accuracy in epoch 18: 96.92%\n",
      "Test set accuracy in epoch 19: 96.91%\n",
      "Test set accuracy in epoch 20: 96.93%\n",
      "Test set accuracy in epoch 21: 97.04%\n",
      "Test set accuracy in epoch 22: 96.92%\n",
      "Test set accuracy in epoch 23: 97.38%\n",
      "Test set accuracy in epoch 24: 96.92%\n",
      "Test set accuracy in epoch 25: 97.17%\n",
      "Test set accuracy in epoch 26: 97.38%\n",
      "Test set accuracy in epoch 27: 96.73%\n",
      "Test set accuracy in epoch 28: 97.37%\n",
      "Test set accuracy in epoch 29: 96.92%\n",
      "Test set accuracy in epoch 30: 97.21%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    adam_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(adam_train_step, feed_dict={adam_X: X_batch, adam_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        adam_test_acc = sess.run(adam_accuracy, feed_dict={adam_X: mnist.test.images, adam_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(adam_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = adam_saver.save(sess, './models/adam_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decaying the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='lrd_X')\n",
    "lrd_y = tf.placeholder(tf.int64, shape=(None, 10), name='lrd_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('lrd_dnn'): # Using bn_neuron_layer because it does not change the netowrk feedforward is the same\n",
    "    lrd_hidden1 = bn_neuron_layer(lrd_X, h1, name='lrd_hidden1', activation='elu')\n",
    "    lrd_hidden2 = bn_neuron_layer(lrd_hidden1, h2, name='lrd_hidden2',activation='elu')\n",
    "    lrd_out = bn_neuron_layer(lrd_hidden2, num_out, name='lrd_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('lrd_loss'):\n",
    "    lrd_entropy = tf.losses.softmax_cross_entropy(onehot_labels=lrd_y, logits=lrd_out)\n",
    "    lrd_loss = tf.reduce_mean(lrd_entropy, name='lrd_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_eta = 1e-2\n",
    "\n",
    "decay_step = 10000 \n",
    "decay_rate = 0.1\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "eta = tf.train.exponential_decay(initial_eta, global_step, decay_step, decay_rate)\n",
    "\n",
    "with tf.name_scope('lrd_train'):\n",
    "    lrd_optimizer = tf.train.AdamOptimizer(learning_rate=eta)\n",
    "    lrd_train_step = lrd_optimizer.minimize(lrd_loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('lrd_eval'):\n",
    "\n",
    "    lrd_predictions = tf.equal(tf.argmax(lrd_out, 1), tf.argmax(lrd_y, 1))\n",
    "    lrd_accuracy = tf.reduce_mean(tf.cast(lrd_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd_init = tf.global_variables_initializer()\n",
    "lrd_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 93.53%\n",
      "Test set accuracy in epoch 2: 95.32%\n",
      "Test set accuracy in epoch 3: 96.17%\n",
      "Test set accuracy in epoch 4: 96.87%\n",
      "Test set accuracy in epoch 5: 97.15%\n",
      "Test set accuracy in epoch 6: 97.34%\n",
      "Test set accuracy in epoch 7: 97.47%\n",
      "Test set accuracy in epoch 8: 97.55%\n",
      "Test set accuracy in epoch 9: 97.76%\n",
      "Test set accuracy in epoch 10: 97.87%\n",
      "Test set accuracy in epoch 11: 97.87%\n",
      "Test set accuracy in epoch 12: 98.11%\n",
      "Test set accuracy in epoch 13: 97.99%\n",
      "Test set accuracy in epoch 14: 98.11%\n",
      "Test set accuracy in epoch 15: 98.13%\n",
      "Test set accuracy in epoch 16: 98.13%\n",
      "Test set accuracy in epoch 17: 98.1%\n",
      "Test set accuracy in epoch 18: 98.09%\n",
      "Test set accuracy in epoch 19: 98.15%\n",
      "Test set accuracy in epoch 20: 98.21%\n",
      "Test set accuracy in epoch 21: 98.2%\n",
      "Test set accuracy in epoch 22: 98.16%\n",
      "Test set accuracy in epoch 23: 98.16%\n",
      "Test set accuracy in epoch 24: 98.17%\n",
      "Test set accuracy in epoch 25: 98.18%\n",
      "Test set accuracy in epoch 26: 98.19%\n",
      "Test set accuracy in epoch 27: 98.19%\n",
      "Test set accuracy in epoch 28: 98.19%\n",
      "Test set accuracy in epoch 29: 98.18%\n",
      "Test set accuracy in epoch 30: 98.18%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    lrd_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(lrd_train_step, feed_dict={lrd_X: X_batch, lrd_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        lrd_test_acc = sess.run(lrd_accuracy, feed_dict={lrd_X: mnist.test.images, lrd_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(lrd_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = lrd_saver.save(sess, './models/lrd_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last updates accuracy is unchanged due to low values of eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='reg_X')\n",
    "reg_y = tf.placeholder(tf.int64, shape=(None, 10), name='reg_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=0.05)\n",
    "        \n",
    "        if activation == 'elu':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=None, weights_initializer=initializer, weights_regularizer= regularizer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            bn_dense = tf.contrib.layers.batch_norm(dense, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            elu = tf.nn.elu(bn_dense)\n",
    "            \n",
    "            return elu\n",
    "        \n",
    "        elif activation == 'softmax':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=tf.nn.softmax, weights_initializer=initializer, weights_regularizer= regularizer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('reg_dnn'): \n",
    "    reg_hidden1 = reg_neuron_layer(reg_X, h1, name='reg_hidden1', activation='elu')\n",
    "    reg_hidden2 = reg_neuron_layer(reg_hidden1, h2, name='reg_hidden2',activation='elu')\n",
    "    reg_out = reg_neuron_layer(reg_hidden2, num_out, name='reg_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('reg_loss'):\n",
    "    reg_entropy = tf.losses.softmax_cross_entropy(onehot_labels=reg_y, logits=reg_out)\n",
    "    reg_loss = tf.reduce_mean(reg_entropy, name='reg_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "eta = tf.train.exponential_decay(initial_eta, global_step, decay_step, decay_rate)\n",
    "\n",
    "with tf.name_scope('reg_train'):\n",
    "    reg_optimizer = tf.train.AdamOptimizer(learning_rate=eta)\n",
    "    reg_train_step = reg_optimizer.minimize(reg_loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('reg_eval'):\n",
    "\n",
    "    reg_predictions = tf.equal(tf.argmax(reg_out, 1), tf.argmax(reg_y, 1))\n",
    "    reg_accuracy = tf.reduce_mean(tf.cast(reg_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_init = tf.global_variables_initializer()\n",
    "reg_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 94.17%\n",
      "Test set accuracy in epoch 2: 95.24%\n",
      "Test set accuracy in epoch 3: 96.26%\n",
      "Test set accuracy in epoch 4: 96.77%\n",
      "Test set accuracy in epoch 5: 97.01%\n",
      "Test set accuracy in epoch 6: 97.3%\n",
      "Test set accuracy in epoch 7: 97.62%\n",
      "Test set accuracy in epoch 8: 97.58%\n",
      "Test set accuracy in epoch 9: 97.71%\n",
      "Test set accuracy in epoch 10: 97.89%\n",
      "Test set accuracy in epoch 11: 97.95%\n",
      "Test set accuracy in epoch 12: 97.88%\n",
      "Test set accuracy in epoch 13: 97.8%\n",
      "Test set accuracy in epoch 14: 97.94%\n",
      "Test set accuracy in epoch 15: 98.0%\n",
      "Test set accuracy in epoch 16: 97.89%\n",
      "Test set accuracy in epoch 17: 97.89%\n",
      "Test set accuracy in epoch 18: 97.95%\n",
      "Test set accuracy in epoch 19: 98.05%\n",
      "Test set accuracy in epoch 20: 97.96%\n",
      "Test set accuracy in epoch 21: 97.99%\n",
      "Test set accuracy in epoch 22: 98.0%\n",
      "Test set accuracy in epoch 23: 97.99%\n",
      "Test set accuracy in epoch 24: 97.99%\n",
      "Test set accuracy in epoch 25: 98.02%\n",
      "Test set accuracy in epoch 26: 98.0%\n",
      "Test set accuracy in epoch 27: 98.0%\n",
      "Test set accuracy in epoch 28: 98.0%\n",
      "Test set accuracy in epoch 29: 98.0%\n",
      "Test set accuracy in epoch 30: 98.01%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    reg_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(reg_train_step, feed_dict={reg_X: X_batch, reg_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        reg_test_acc = sess.run(reg_accuracy, feed_dict={reg_X: mnist.test.images, reg_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(reg_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = reg_saver.save(sess, './models/reg_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='drop_X')\n",
    "drop_y = tf.placeholder(tf.int64, shape=(None, 10), name='drop_y')\n",
    "prob = tf.placeholder_with_default(1.0, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=0.05)\n",
    "        \n",
    "        if activation == 'elu':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=None, weights_initializer=initializer, weights_regularizer= regularizer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            bn_dense = tf.contrib.layers.batch_norm(dense, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            dropout = tf.contrib.layers.dropout(bn_dense, keep_prob=prob)\n",
    "            elu = tf.nn.elu(dropout)\n",
    "            \n",
    "            return bn_dense\n",
    "        \n",
    "        elif activation == 'softmax':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=tf.nn.softmax, weights_initializer=initializer, weights_regularizer= regularizer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('drop_dnn'): \n",
    "    drop_hidden1 = drop_neuron_layer(drop_X, h1, name='drop_hidden1', activation='elu')\n",
    "    drop_hidden2 = drop_neuron_layer(drop_hidden1, h2, name='drop_hidden2',activation='elu')\n",
    "    drop_out = drop_neuron_layer(drop_hidden2, num_out, name='drop_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('drop_loss'):\n",
    "    drop_entropy = tf.losses.softmax_cross_entropy(onehot_labels=drop_y, logits=drop_out)\n",
    "    drop_loss = tf.reduce_mean(drop_entropy, name='drop_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('drop_train'):\n",
    "    drop_optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    drop_train_step = drop_optimizer.minimize(drop_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('drop_eval'):\n",
    "\n",
    "    drop_predictions = tf.equal(tf.argmax(drop_out, 1), tf.argmax(drop_y, 1))\n",
    "    drop_accuracy = tf.reduce_mean(tf.cast(drop_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_init = tf.global_variables_initializer()\n",
    "drop_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 90.24%\n",
      "Test set accuracy in epoch 2: 91.16%\n",
      "Test set accuracy in epoch 3: 90.78%\n",
      "Test set accuracy in epoch 4: 91.11%\n",
      "Test set accuracy in epoch 5: 91.36%\n",
      "Test set accuracy in epoch 6: 91.41%\n",
      "Test set accuracy in epoch 7: 92.23%\n",
      "Test set accuracy in epoch 8: 91.92%\n",
      "Test set accuracy in epoch 9: 90.99%\n",
      "Test set accuracy in epoch 10: 92.31%\n",
      "Test set accuracy in epoch 11: 91.79%\n",
      "Test set accuracy in epoch 12: 91.55%\n",
      "Test set accuracy in epoch 13: 92.05%\n",
      "Test set accuracy in epoch 14: 91.96%\n",
      "Test set accuracy in epoch 15: 92.33%\n",
      "Test set accuracy in epoch 16: 92.42%\n",
      "Test set accuracy in epoch 17: 92.14%\n",
      "Test set accuracy in epoch 18: 92.33%\n",
      "Test set accuracy in epoch 19: 91.87%\n",
      "Test set accuracy in epoch 20: 92.36%\n",
      "Test set accuracy in epoch 21: 91.82%\n",
      "Test set accuracy in epoch 22: 91.8%\n",
      "Test set accuracy in epoch 23: 92.06%\n",
      "Test set accuracy in epoch 24: 92.13%\n",
      "Test set accuracy in epoch 25: 92.37%\n",
      "Test set accuracy in epoch 26: 92.31%\n",
      "Test set accuracy in epoch 27: 92.03%\n",
      "Test set accuracy in epoch 28: 92.41%\n",
      "Test set accuracy in epoch 29: 91.97%\n",
      "Test set accuracy in epoch 30: 92.16%\n",
      "Test set accuracy in epoch 31: 92.25%\n",
      "Test set accuracy in epoch 32: 92.26%\n",
      "Test set accuracy in epoch 33: 92.24%\n",
      "Test set accuracy in epoch 34: 92.25%\n",
      "Test set accuracy in epoch 35: 92.59%\n",
      "Test set accuracy in epoch 36: 92.1%\n",
      "Test set accuracy in epoch 37: 92.19%\n",
      "Test set accuracy in epoch 38: 92.19%\n",
      "Test set accuracy in epoch 39: 92.38%\n",
      "Test set accuracy in epoch 40: 92.09%\n",
      "Test set accuracy in epoch 41: 92.22%\n",
      "Test set accuracy in epoch 42: 92.31%\n",
      "Test set accuracy in epoch 43: 92.23%\n",
      "Test set accuracy in epoch 44: 92.67%\n",
      "Test set accuracy in epoch 45: 92.48%\n",
      "Test set accuracy in epoch 46: 92.63%\n",
      "Test set accuracy in epoch 47: 92.54%\n",
      "Test set accuracy in epoch 48: 92.35%\n",
      "Test set accuracy in epoch 49: 92.04%\n",
      "Test set accuracy in epoch 50: 92.27%\n",
      "Test set accuracy in epoch 51: 92.25%\n",
      "Test set accuracy in epoch 52: 92.56%\n",
      "Test set accuracy in epoch 53: 92.56%\n",
      "Test set accuracy in epoch 54: 92.69%\n",
      "Test set accuracy in epoch 55: 92.42%\n",
      "Test set accuracy in epoch 56: 92.29%\n",
      "Test set accuracy in epoch 57: 92.63%\n",
      "Test set accuracy in epoch 58: 92.57%\n",
      "Test set accuracy in epoch 59: 92.11%\n",
      "Test set accuracy in epoch 60: 92.54%\n",
      "Test set accuracy in epoch 61: 92.42%\n",
      "Test set accuracy in epoch 62: 92.58%\n",
      "Test set accuracy in epoch 63: 92.35%\n",
      "Test set accuracy in epoch 64: 92.67%\n",
      "Test set accuracy in epoch 65: 92.53%\n",
      "Test set accuracy in epoch 66: 92.47%\n",
      "Test set accuracy in epoch 67: 92.63%\n",
      "Test set accuracy in epoch 68: 92.26%\n",
      "Test set accuracy in epoch 69: 92.57%\n",
      "Test set accuracy in epoch 70: 92.35%\n",
      "Test set accuracy in epoch 71: 92.5%\n",
      "Test set accuracy in epoch 72: 92.48%\n",
      "Test set accuracy in epoch 73: 92.32%\n",
      "Test set accuracy in epoch 74: 92.47%\n",
      "Test set accuracy in epoch 75: 91.91%\n",
      "Test set accuracy in epoch 76: 92.0%\n",
      "Test set accuracy in epoch 77: 92.5%\n",
      "Test set accuracy in epoch 78: 92.78%\n",
      "Test set accuracy in epoch 79: 91.68%\n",
      "Test set accuracy in epoch 80: 92.31%\n",
      "Test set accuracy in epoch 81: 92.62%\n",
      "Test set accuracy in epoch 82: 92.69%\n",
      "Test set accuracy in epoch 83: 93.0%\n",
      "Test set accuracy in epoch 84: 92.41%\n",
      "Test set accuracy in epoch 85: 92.85%\n",
      "Test set accuracy in epoch 86: 92.82%\n",
      "Test set accuracy in epoch 87: 92.34%\n",
      "Test set accuracy in epoch 88: 92.8%\n",
      "Test set accuracy in epoch 89: 92.67%\n",
      "Test set accuracy in epoch 90: 92.69%\n",
      "Test set accuracy in epoch 91: 92.38%\n",
      "Test set accuracy in epoch 92: 92.2%\n",
      "Test set accuracy in epoch 93: 92.36%\n",
      "Test set accuracy in epoch 94: 92.27%\n",
      "Test set accuracy in epoch 95: 92.34%\n",
      "Test set accuracy in epoch 96: 92.01%\n",
      "Test set accuracy in epoch 97: 92.17%\n",
      "Test set accuracy in epoch 98: 92.61%\n",
      "Test set accuracy in epoch 99: 92.23%\n",
      "Test set accuracy in epoch 100: 92.73%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    drop_init.run()\n",
    "    for epoch in range(100): # Needs more epochs to work\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(drop_train_step, feed_dict={drop_X: X_batch, drop_y: y_batch, prob: 0.5})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        drop_test_acc = sess.run(drop_accuracy, feed_dict={drop_X: mnist.test.images, drop_y:np.eye(10)[mnist.test.labels], prob: 1.0})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(drop_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = drop_saver.save(sess, './models/drop_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
