{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feed Forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 28*28 # MNIST\n",
    "h1 = 300 # hidden layer 1,2 size\n",
    "h2 = 100 \n",
    "num_out = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None, 10), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Function For Neuron Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, num_neurons, name, activation= None):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        variance = 2 / np.sqrt(num_inputs)\n",
    "        \n",
    "        W = tf.Variable(tf.truncated_normal((num_inputs, num_neurons), stddev=variance), name='weights')\n",
    "        b = tf.Variable(tf.zeros([num_neurons]), name='bias')\n",
    "        \n",
    "        z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is None:\n",
    "            return z\n",
    "\n",
    "        activation = activation.lower()\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(z)\n",
    "        elif activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(z)\n",
    "        elif activation == 'softmax':\n",
    "            return tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all layers of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(X, h1, name='hidden1', activation='ReLU')\n",
    "    hidden2 = neuron_layer(hidden1, h2, name='hidden2',activation='ReLU')\n",
    "    out = neuron_layer(hidden2, num_out, name='out', activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=out)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "\n",
    "    predictions = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Initializer and Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD MNIST AND TRAIN NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./tmp/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 64.11%\n",
      "Test set accuracy in epoch 2: 66.02%\n",
      "Test set accuracy in epoch 3: 66.5%\n",
      "Test set accuracy in epoch 4: 66.78%\n",
      "Test set accuracy in epoch 5: 67.0%\n",
      "Test set accuracy in epoch 6: 67.23%\n",
      "Test set accuracy in epoch 7: 67.35%\n",
      "Test set accuracy in epoch 8: 67.49%\n",
      "Test set accuracy in epoch 9: 67.7%\n",
      "Test set accuracy in epoch 10: 67.74%\n",
      "Test set accuracy in epoch 11: 67.89%\n",
      "Test set accuracy in epoch 12: 67.89%\n",
      "Test set accuracy in epoch 13: 67.98%\n",
      "Test set accuracy in epoch 14: 68.03%\n",
      "Test set accuracy in epoch 15: 68.06%\n",
      "Test set accuracy in epoch 16: 68.07%\n",
      "Test set accuracy in epoch 17: 68.15%\n",
      "Test set accuracy in epoch 18: 68.22%\n",
      "Test set accuracy in epoch 19: 68.22%\n",
      "Test set accuracy in epoch 20: 77.22%\n",
      "Test set accuracy in epoch 21: 77.52%\n",
      "Test set accuracy in epoch 22: 77.58%\n",
      "Test set accuracy in epoch 23: 77.69%\n",
      "Test set accuracy in epoch 24: 77.8%\n",
      "Test set accuracy in epoch 25: 77.79%\n",
      "Test set accuracy in epoch 26: 77.91%\n",
      "Test set accuracy in epoch 27: 77.94%\n",
      "Test set accuracy in epoch 28: 77.97%\n",
      "Test set accuracy in epoch 29: 77.99%\n",
      "Test set accuracy in epoch 30: 78.04%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(train_step, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: mnist.test.images, y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = saver.save(sess, './models/final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He Initialization + ELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_elu_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='he_elu_X')\n",
    "he_elu_y = tf.placeholder(tf.int64, shape=(None, 10), name='he_elu_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_elu_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        W = tf.Variable(initializer((num_inputs, num_neurons)), name='weights')\n",
    "        b = tf.Variable(tf.zeros([num_neurons]), name='he_elu_bias')\n",
    "        \n",
    "        z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation is None:\n",
    "            return z\n",
    "\n",
    "        activation = activation.lower()\n",
    "        if activation == 'elu':\n",
    "            return tf.nn.elu(z)\n",
    "        elif activation == 'softmax':\n",
    "            return tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_dnn'):\n",
    "    he_elu_hidden1 = he_elu_neuron_layer(he_elu_X, h1, name='he_elu_hidden1', activation='elu')\n",
    "    he_elu_hidden2 = he_elu_neuron_layer(he_elu_hidden1, h2, name='he_elu_hidden2',activation='elu')\n",
    "    he_elu_out = he_elu_neuron_layer(he_elu_hidden2, num_out, name='he_elu_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_loss'):\n",
    "    he_elu_entropy = tf.losses.softmax_cross_entropy(onehot_labels=he_elu_y, logits=he_elu_out)\n",
    "    he_elu_loss = tf.reduce_mean(he_elu_entropy, name='he_elu_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('he_elu_train'):\n",
    "    he_elu_optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    he_elu_train_step = he_elu_optimizer.minimize(he_elu_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('he_elu_eval'):\n",
    "\n",
    "    he_elu_predictions = tf.equal(tf.argmax(he_elu_out, 1), tf.argmax(he_elu_y, 1))\n",
    "    he_elu_accuracy = tf.reduce_mean(tf.cast(he_elu_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_elu_init = tf.global_variables_initializer()\n",
    "he_elu_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 72.8%\n",
      "Test set accuracy in epoch 2: 76.03%\n",
      "Test set accuracy in epoch 3: 81.1%\n",
      "Test set accuracy in epoch 4: 82.04%\n",
      "Test set accuracy in epoch 5: 82.61%\n",
      "Test set accuracy in epoch 6: 82.83%\n",
      "Test set accuracy in epoch 7: 90.48%\n",
      "Test set accuracy in epoch 8: 91.07%\n",
      "Test set accuracy in epoch 9: 91.19%\n",
      "Test set accuracy in epoch 10: 91.54%\n",
      "Test set accuracy in epoch 11: 91.77%\n",
      "Test set accuracy in epoch 12: 91.96%\n",
      "Test set accuracy in epoch 13: 92.11%\n",
      "Test set accuracy in epoch 14: 92.28%\n",
      "Test set accuracy in epoch 15: 92.44%\n",
      "Test set accuracy in epoch 16: 92.54%\n",
      "Test set accuracy in epoch 17: 92.69%\n",
      "Test set accuracy in epoch 18: 92.68%\n",
      "Test set accuracy in epoch 19: 92.71%\n",
      "Test set accuracy in epoch 20: 92.78%\n",
      "Test set accuracy in epoch 21: 92.91%\n",
      "Test set accuracy in epoch 22: 92.97%\n",
      "Test set accuracy in epoch 23: 93.07%\n",
      "Test set accuracy in epoch 24: 93.05%\n",
      "Test set accuracy in epoch 25: 93.22%\n",
      "Test set accuracy in epoch 26: 93.21%\n",
      "Test set accuracy in epoch 27: 93.29%\n",
      "Test set accuracy in epoch 28: 93.35%\n",
      "Test set accuracy in epoch 29: 93.42%\n",
      "Test set accuracy in epoch 30: 93.46%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    he_elu_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(he_elu_train_step, feed_dict={he_elu_X: X_batch, he_elu_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        he_elu_test_acc = sess.run(he_elu_accuracy, feed_dict={he_elu_X: mnist.test.images, he_elu_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(he_elu_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = he_elu_saver.save(sess, './models/he_elu_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='bn_X')\n",
    "bn_y = tf.placeholder(tf.int64, shape=(None, 10), name='bn_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_neuron_layer(X, num_neurons, name, activation):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        num_inputs = int(X.get_shape()[1])\n",
    "        \n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        \n",
    "        if activation == 'elu':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=tf.nn.elu, weights_initializer=initializer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            bn_dense = tf.contrib.layers.batch_norm(dense, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            return bn_dense\n",
    "        \n",
    "        elif activation == 'softmax':\n",
    "            dense = tf.contrib.layers.fully_connected(X, num_neurons, activation_fn=tf.nn.softmax, weights_initializer=initializer, scope=name, reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_dnn'):\n",
    "    bn_hidden1 = bn_neuron_layer(bn_X, h1, name='bn_hidden1', activation='elu')\n",
    "    bn_hidden2 = bn_neuron_layer(bn_hidden1, h2, name='bn_hidden2',activation='elu')\n",
    "    bn_out = bn_neuron_layer(bn_hidden2, num_out, name='bn_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_loss'):\n",
    "    bn_entropy = tf.losses.softmax_cross_entropy(onehot_labels=bn_y, logits=bn_out)\n",
    "    bn_loss = tf.reduce_mean(bn_entropy, name='bn_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('bn_train'):\n",
    "    bn_optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "    bn_train_step = bn_optimizer.minimize(bn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('bn_eval'):\n",
    "\n",
    "    bn_predictions = tf.equal(tf.argmax(bn_out, 1), tf.argmax(bn_y, 1))\n",
    "    bn_accuracy = tf.reduce_mean(tf.cast(bn_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_init = tf.global_variables_initializer()\n",
    "bn_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 88.45%\n",
      "Test set accuracy in epoch 2: 90.8%\n",
      "Test set accuracy in epoch 3: 91.58%\n",
      "Test set accuracy in epoch 4: 92.15%\n",
      "Test set accuracy in epoch 5: 92.47%\n",
      "Test set accuracy in epoch 6: 92.85%\n",
      "Test set accuracy in epoch 7: 92.91%\n",
      "Test set accuracy in epoch 8: 93.17%\n",
      "Test set accuracy in epoch 9: 93.39%\n",
      "Test set accuracy in epoch 10: 93.54%\n",
      "Test set accuracy in epoch 11: 93.76%\n",
      "Test set accuracy in epoch 12: 93.98%\n",
      "Test set accuracy in epoch 13: 94.15%\n",
      "Test set accuracy in epoch 14: 94.34%\n",
      "Test set accuracy in epoch 15: 94.47%\n",
      "Test set accuracy in epoch 16: 94.64%\n",
      "Test set accuracy in epoch 17: 94.74%\n",
      "Test set accuracy in epoch 18: 94.86%\n",
      "Test set accuracy in epoch 19: 94.99%\n",
      "Test set accuracy in epoch 20: 95.06%\n",
      "Test set accuracy in epoch 21: 95.12%\n",
      "Test set accuracy in epoch 22: 95.2%\n",
      "Test set accuracy in epoch 23: 95.26%\n",
      "Test set accuracy in epoch 24: 95.36%\n",
      "Test set accuracy in epoch 25: 95.48%\n",
      "Test set accuracy in epoch 26: 95.46%\n",
      "Test set accuracy in epoch 27: 95.56%\n",
      "Test set accuracy in epoch 28: 95.64%\n",
      "Test set accuracy in epoch 29: 95.76%\n",
      "Test set accuracy in epoch 30: 95.86%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    bn_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(bn_train_step, feed_dict={bn_X: X_batch, bn_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        bn_test_acc = sess.run(bn_accuracy, feed_dict={bn_X: mnist.test.images, bn_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(bn_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = bn_saver.save(sess, './models/bn_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_X = tf.placeholder(tf.float32, shape=(None, num_inputs), name='adam_X')\n",
    "adam_y = tf.placeholder(tf.int64, shape=(None, 10), name='adam_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_dnn'): # Using bn_neuron_layer because it does not change the netowrk feedforward is the same\n",
    "    adam_hidden1 = bn_neuron_layer(adam_X, h1, name='adam_hidden1', activation='elu')\n",
    "    adam_hidden2 = bn_neuron_layer(adam_hidden1, h2, name='adam_hidden2',activation='elu')\n",
    "    adam_out = bn_neuron_layer(adam_hidden2, num_out, name='adam_out', activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_loss'):\n",
    "    adam_entropy = tf.losses.softmax_cross_entropy(onehot_labels=adam_y, logits=adam_out)\n",
    "    adam_loss = tf.reduce_mean(adam_entropy, name='adam_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "\n",
    "with tf.name_scope('adam_train'):\n",
    "    adam_optimizer = tf.train.AdamOptimizer(learning_rate=eta)\n",
    "    adam_train_step = adam_optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('adam_eval'):\n",
    "\n",
    "    adam_predictions = tf.equal(tf.argmax(adam_out, 1), tf.argmax(adam_y, 1))\n",
    "    adam_accuracy = tf.reduce_mean(tf.cast(adam_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_init = tf.global_variables_initializer()\n",
    "adam_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy in epoch 1: 95.22%\n",
      "Test set accuracy in epoch 2: 95.81%\n",
      "Test set accuracy in epoch 3: 95.95%\n",
      "Test set accuracy in epoch 4: 96.52%\n",
      "Test set accuracy in epoch 5: 96.45%\n",
      "Test set accuracy in epoch 6: 96.68%\n",
      "Test set accuracy in epoch 7: 96.88%\n",
      "Test set accuracy in epoch 8: 96.61%\n",
      "Test set accuracy in epoch 9: 96.84%\n",
      "Test set accuracy in epoch 10: 96.97%\n",
      "Test set accuracy in epoch 11: 96.78%\n",
      "Test set accuracy in epoch 12: 96.86%\n",
      "Test set accuracy in epoch 13: 97.34%\n",
      "Test set accuracy in epoch 14: 97.12%\n",
      "Test set accuracy in epoch 15: 97.16%\n",
      "Test set accuracy in epoch 16: 97.29%\n",
      "Test set accuracy in epoch 17: 96.83%\n",
      "Test set accuracy in epoch 18: 97.05%\n",
      "Test set accuracy in epoch 19: 97.24%\n",
      "Test set accuracy in epoch 20: 97.41%\n",
      "Test set accuracy in epoch 21: 97.42%\n",
      "Test set accuracy in epoch 22: 97.21%\n",
      "Test set accuracy in epoch 23: 97.25%\n",
      "Test set accuracy in epoch 24: 97.46%\n",
      "Test set accuracy in epoch 25: 97.51%\n",
      "Test set accuracy in epoch 26: 97.12%\n",
      "Test set accuracy in epoch 27: 97.55%\n",
      "Test set accuracy in epoch 28: 97.14%\n",
      "Test set accuracy in epoch 29: 97.29%\n",
      "Test set accuracy in epoch 30: 97.17%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    adam_init.run()\n",
    "    for epoch in range(30):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            # get next batch\n",
    "            X_batch_temp, y_batch_temp = mnist.train.next_batch(batch_size)\n",
    "            X_batch = np.reshape(X_batch_temp, [-1, 784])\n",
    "            y_batch = np.eye(10)[y_batch_temp] # numpy one-hot encoding\n",
    "            \n",
    "            # execute update step \n",
    "            sess.run(adam_train_step, feed_dict={adam_X: X_batch, adam_y: y_batch})\n",
    "            \n",
    "        # Evaluate accuracy on test set\n",
    "        adam_test_acc = sess.run(adam_accuracy, feed_dict={adam_X: mnist.test.images, adam_y:np.eye(10)[mnist.test.labels]})\n",
    "        \n",
    "        print(f'Test set accuracy in epoch {epoch+1}: {round(adam_test_acc*100, 2)}%')\n",
    "            \n",
    "    # save model\n",
    "    save_path = adam_saver.save(sess, './models/adam_final_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decaying the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
